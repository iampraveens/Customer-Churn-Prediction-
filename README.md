# ğŸ“Š Customer Churn Prediction

[![Python](https://img.shields.io/badge/Python-3.10%2B-blue.svg)](https://www.python.org/) [![scikit-learn](https://img.shields.io/badge/scikitLearn-1.5.1-green.svg)](https://opensource.org/licenses/MIT) [![MLflow](https://img.shields.io/badge/MLflow-3.3.2-blueviolet.svg)](https://mlflow.org/) [![DVC](https://img.shields.io/badge/DVC-3.62.0-orange.svg)](https://dvc.org/) [![DagsHub](https://img.shields.io/badge/DagsHub-0.6.3-red.svg)](https://dvc.org/)

A complete **end-to-end machine learning project** that predicts customer churn for a telecom company. The project includes **data pipelines with DVC**, **experiment tracking with MLflow/DagsHub**, and a **Flask web application** for real-time churn prediction.

## ğŸš€ Project Overview

Customer churn is one of the most critical problems in the telecom industry. This project leverages machine learning techniques to predict whether a customer is likely to churn, helping businesses take proactive measures to retain them.

# ğŸš€ Key Features

- End-to-End ML Pipeline with stages:
  - Data ingestion
  - Data validation
  - Data preprocessing & transformation
  - Model training (Logistic Regression, Random Forest, XGBoost)
  - Model evaluation (Accuracy, F1, Recall, AUC, Confusion Matrix, ROC Curve)
- Data Version Control (DVC) for pipeline reproducibility
- MLflow + Dagshub integration for experiment tracking and model registry
- Class imbalance handling with SMOTEENN / ADASYN
- Feature engineering for improved model performance
- Flask Web App for real-time churn prediction
- Deployment Ready on Render/Heroku with gunicorn

## ğŸ› ï¸ Installation & Setup

### 1. Clone the repository

```bash
https://github.com/iampraveens/Customer-Churn-Prediction-.git
cd Customer-Churn-Prediction-
```

### 2. Create and activate virtual environment

```bash
python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scripts\activate      # Windows
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Run ML pipeline (DVC)

```bash
dvc repro
```

### 5. Run Flask app locally

```bash
flask run --host=0.0.0.0 --port=8000
```

---

## â˜ï¸ DVC Remote on DagsHub (Stepâ€‘byâ€‘Step)

> Use these exact commands to connect your DVC pipeline to DagsHub and push artifacts.

```bash
# Initialize DVC in this repository
dvc init

# Add DagsHub as your DVC remote (replace with your username/repo)
dvc remote add origin https://dagshub.com/<username>/<repo>.dvc

# Make it the default remote
dvc remote default origin
```

**Create a DagsHub Personal Access Token**

1. Open: [https://dagshub.com/settings/tokens](https://dagshub.com/settings/tokens)
2. **Generate New Token** â†’ name it e.g. `dvc_token`
3. Copy the token (youâ€™ll use it as password below)

```bash
# Configure auth for the DVC remote (stored only locally)
dvc remote modify origin --local auth basic
# Use your DagsHub username
dvc remote modify origin --local user your-username
# Paste the personal access token as the password
dvc remote modify origin --local password <YOUR_TOKEN>

# Run the full pipeline and push artifacts to DagsHub
dvc repro
dvc push

# Commit & push code + DVC metadata to GitHub/DagsHub
git add .
git commit -m "Run pipeline and push DVC artifacts"
git push origin main
```

> **Tip:** If a stage is skipped by `dvc repro`, make a minimal change (e.g., bump a param in `params.yaml`) or remove the stage outputs to force reâ€‘run.

---

## ğŸ§ª MLflow + DagsHub Tracking

Track experiments to DagsHubâ€™s MLflow server either **inâ€‘code** (recommended) or via **environment variables**.

### Option A â€” Inâ€‘code initialization (recommended)

```python
# src/CustomerChurn/utils/mlflow.py
import dagshub
import mlflow.sklearn

def setup_mlflow():
    dagshub.init(
        repo_owner="iampraveens",
        repo_name="Customer-Churn-Prediction-",
        mlflow=True,
        dvc=True,
    )
    mlflow.sklearn.autolog()
```

Use inside training/evaluation:

```python
with mlflow.start_run():
    # your fit / predict / log code
    ...
```

### Option B â€” Environment variables (CI/servers, no interactive login)

```bash
# Point MLflow to DagsHubâ€™s tracking server
export MLFLOW_TRACKING_URI="https://dagshub.com/iampraveens/Customer-Churn-Prediction-.mlflow"

# Basic auth with your DagsHub username + token
export MLFLOW_TRACKING_USERNAME="iampraveens"
export MLFLOW_TRACKING_PASSWORD="<YOUR_TOKEN>"
```

Then, in code, you can use MLflow normally:

```python
import mlflow
with mlflow.start_run():
    mlflow.log_param("chosen_model", model_name)
    mlflow.log_metric("accuracy", acc)
```

> **Where to see runs?**\
> Your runs and metrics will be visible at:\
> `https://dagshub.com/iampraveens/Customer-Churn-Prediction-.mlflow`

---

## ğŸ’» Usage Example

1. Open the Flask app in browser: `http://127.0.0.1:8000`
2. Fill in customer details in the form
3. Get churn prediction result with probability score:

```text
âš ï¸ Customer is likely to churn.
Churn Probability: 0.75

âœ… Customer is not likely to churn.
Churn Probability: 0.20
```

---

## ğŸ“‚ Project Structure

```
iampraveens-customer-churn-prediction-/
â”œâ”€â”€ README.md                  # Project documentation
â”œâ”€â”€ app.py                     # Flask web application
â”œâ”€â”€ dvc.lock                   # DVC lock file for reproducibility
â”œâ”€â”€ dvc.yaml                   # DVC pipeline stages
â”œâ”€â”€ LICENSE                    # MIT License
â”œâ”€â”€ main.py                    # Main pipeline orchestrator
â”œâ”€â”€ params.yaml                # Model hyperparameters and configs
â”œâ”€â”€ Procfile                   # For Heroku deployment
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ schema.yaml                # Data schema for validation
â”œâ”€â”€ setup.py                   # Package setup
â”œâ”€â”€ template.py                # Project scaffolding script
â”œâ”€â”€ .dvcignore                 # DVC ignore patterns
â”œâ”€â”€ artifacts/                 # Pipeline outputs (data, models, metrics)
â”‚   â”œâ”€â”€ data_ingestion/        # Ingested raw data
â”‚   â”œâ”€â”€ data_preprocessing/    # Cleaned data
â”‚   â”œâ”€â”€ data_transformation/   # Transformed train/test sets
â”‚   â”œâ”€â”€ data_validation/       # Validation status
â”‚   â”œâ”€â”€ model_evaluation/      # Metrics and plots
â”‚   â””â”€â”€ model_trainer/         # Trained models
â”œâ”€â”€ config/                    # Configuration files
â”‚   â””â”€â”€ config.yaml
â”œâ”€â”€ research/                  # Jupyter notebooks for experiments
â”‚   â”œâ”€â”€ 01_data_ingestion.ipynb
â”‚   â”œâ”€â”€ 02_data_validation.ipynb
â”‚   â”œâ”€â”€ 03_data_preprocessing.ipynb
â”‚   â”œâ”€â”€ 04_data_transformation.ipynb
â”‚   â”œâ”€â”€ 05_model_training.ipynb
â”‚   â”œâ”€â”€ 06_model_evaluation.ipynb
â”‚   â”œâ”€â”€ experiments.ipynb
â”‚   â””â”€â”€ trials.ipynb
â”œâ”€â”€ saved_models/              # Persisted models for app
â”‚   â””â”€â”€ model.joblib
â”œâ”€â”€ src/                       # Source code
â”‚   â””â”€â”€ CustomerChurn/
â”‚       â”œâ”€â”€ components/        # Pipeline components (ingestion, validation, etc.)
â”‚       â”œâ”€â”€ config/            # Config management
â”‚       â”œâ”€â”€ constants/         # Constants like file paths
â”‚       â”œâ”€â”€ entity/            # Data classes for configs
â”‚       â”œâ”€â”€ pipeline/          # Pipeline stage scripts
â”‚       â””â”€â”€ utils/             # Utilities (YAML reading, MLflow setup)
â”œâ”€â”€ static/                    # Web app static files
â”‚   â””â”€â”€ css/
â”‚       â”œâ”€â”€ style.css
â”‚       â””â”€â”€ js/
â”‚           â””â”€â”€ scripts.js
â”œâ”€â”€ templates/                 # Flask HTML templates
â”‚   â”œâ”€â”€ index.html             # Input form
â”‚   â””â”€â”€ result.html            # Prediction result
â””â”€â”€ .dvc/                      # DVC configuration
    â”œâ”€â”€ config
    â””â”€â”€ .gitignore
```

---

## ğŸ“¦ Dependencies

- Python 3.10+
- Flask
- Scikit-learn
- XGBoost
- Pandas, NumPy
- Matplotlib, Seaborn
- Imbalanced-learn
- DVC
- MLflow
- Dagshub

Install via:

```bash
pip install -r requirements.txt
```

---

## ğŸ¤ Contribution Guidelines

Contributions are welcome! To contribute:

1. Fork the repo
2. Create a new branch (`feature-xyz`)
3. Commit your changes
4. Push the branch
5. Open a Pull Request

---

## ğŸ“œ License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.

---

## ğŸ‘¨â€ğŸ’» Author

Developed with â¤ï¸ by **Praveen S** ([GitHub](https://github.com/iampraveens))
